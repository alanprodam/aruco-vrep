{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to remote API server\n",
      "Versão OpenCV:  3.4.2\n",
      "Versão Python:  3.6.5\n"
     ]
    }
   ],
   "source": [
    "# print('Program started')\n",
    "import vrep\n",
    "import numpy as np\n",
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import sys, time, math\n",
    "from platform import python_version\n",
    "\n",
    "##############Comunicação com V-REP##########################\n",
    "serverIP = '127.0.0.1';\n",
    "serverPort = 19999; #Esta porta do servidor está sempre aberta\n",
    "vrep.simxFinish(-1);\n",
    "clientID=vrep.simxStart(serverIP,serverPort,True,True,5000,5);\n",
    "#############################################################\n",
    "\n",
    "###############################################################################\n",
    "#------- ROTATIONS https://www.learnopencv.com/rotation-matrix-to-euler-angles/\n",
    "\n",
    "# Checks if a matrix is a valid rotation matrix.\n",
    "def isRotationMatrix(R):\n",
    "    Rt = np.transpose(R)\n",
    "    shouldBeIdentity = np.dot(Rt, R)\n",
    "    I = np.identity(3, dtype=R.dtype)\n",
    "    n = np.linalg.norm(I - shouldBeIdentity)\n",
    "    return n < 1e-6\n",
    "\n",
    "\n",
    "# Calculates rotation matrix to euler angles\n",
    "# The result is the same as MATLAB except the order\n",
    "# of the euler angles ( x and z are swapped ).\n",
    "def rotationMatrixToEulerAngles(R):\n",
    "    assert (isRotationMatrix(R))\n",
    "\n",
    "    sy = math.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])\n",
    "\n",
    "    singular = sy < 1e-6\n",
    "\n",
    "    if not singular:\n",
    "        x = math.atan2(R[2, 1], R[2, 2])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = math.atan2(R[1, 0], R[0, 0])\n",
    "    else:\n",
    "        x = math.atan2(-R[1, 2], R[1, 1])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = 0\n",
    "\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "#-- Update fps\n",
    "def update_fps_read():\n",
    "    global t_read, fps_read\n",
    "    t           = time.time()\n",
    "    fps_read    = 1.0/(t - t_read)\n",
    "    t_read      = t\n",
    "    \n",
    "def update_fps_detect():\n",
    "    global t_detect, fps_detect\n",
    "    t           = time.time()\n",
    "    fps_detect  = 1.0/(t - t_detect)\n",
    "    t_detect      = t\n",
    "    \n",
    "t_read      = time.time()\n",
    "t_detect    = t_read\n",
    "fps_read    = 0.0\n",
    "fps_detect  = 0.0\n",
    "    \n",
    "###############################################################################\n",
    "\n",
    "windowName = \"Imagem-Processada\" #Name of the window created\n",
    "#cv2.namedWindow(windowName, cv2.WINDOW_NORMAL)#Setting the name ande type of window\n",
    "#cv2.setWindowProperty(windowName, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_KEEPRATIO)#setting fullscreen\n",
    "\n",
    "#-- Define Tag\n",
    "id_to_find = 2\n",
    "marker_size = 100 #-cm\n",
    "\n",
    "#-- Get the camera calibration\n",
    "calib_path = ''\n",
    "camera_matrix = np.loadtxt(calib_path+'cameraMatrix.txt', delimiter = ',')\n",
    "camera_distortion = np.loadtxt(calib_path+'cameraDistortion.txt', delimiter = ',')\n",
    "\n",
    "#-- 180 deg rotation matrix around x axis\n",
    "R_flip = np.zeros((3,3), dtype=np.float)\n",
    "R_flip[0,0] = 1.0\n",
    "R_flip[1,1] = -1.0\n",
    "R_flip[2,2] = -1.0\n",
    "\n",
    "#-- Font for the text in the image\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "#-- Define the Aruco dictionary\n",
    "aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_50)\n",
    "parameters =  aruco.DetectorParameters_create()\n",
    "\n",
    "if clientID!=-1:\n",
    "    print ('Connected to remote API server')\n",
    "    print ('Versão OpenCV: ',cv2.__version__)\n",
    "    print ('Versão Python: ',python_version())\n",
    "    \n",
    "    err,visionHandle = vrep.simxGetObjectHandle(clientID,'Vision_sensor',vrep.simx_opmode_oneshot_wait)\n",
    "    \n",
    "    while err == 0:\n",
    "        \n",
    "        update_fps_read()\n",
    "        \n",
    "        err,visionHandle = vrep.simxGetObjectHandle(clientID,'Vision_sensor',vrep.simx_opmode_oneshot_wait)\n",
    "        err,tgHandle=vrep.simxGetObjectHandle(clientID,'Quadricopter_target',vrep.simx_opmode_oneshot_wait)\n",
    "        \n",
    "        err, pos = vrep.simxGetObjectPosition(clientID,tgHandle,tgHandle,vrep.simx_opmode_oneshot_wait) #Posição do objeto a ser seguido pelo Drone.\n",
    "        err, ori = vrep.simxGetObjectOrientation(clientID,tgHandle,-1,vrep.simx_opmode_oneshot_wait) #Orientação do objeto a ser seguido pelo Drone.\n",
    "        \n",
    "        err,res,imgList = vrep.simxGetVisionSensorImage(clientID,visionHandle,0,vrep.simx_opmode_oneshot_wait) #Imagens do sensor\n",
    "        \n",
    "        #-- Convert the list of image to array and invert to get a good plot\n",
    "        img = (np.array(imgList))[::-1]#Passa de lista para uma array e inverte a array para plotar corretamente\n",
    "        \n",
    "        #-- Segment the image in one image of size 1280x720 or 640x480\n",
    "        imgRGB = cv2.flip(np.uint8(img.reshape(512,512,3)),1) #Transforma em uma imagem RGB e espelha\n",
    "        \n",
    "        #-- Convert in gray scale\n",
    "        gray = cv2.cvtColor(imgRGB, cv2.COLOR_BGR2GRAY) #-- remember, OpenCV stores color images in Blue, Green, Red\n",
    "        \n",
    "        #-- Find all the aruco markers in the image\n",
    "        corners, ids, rejected = aruco.detectMarkers(image=gray, \n",
    "                                                     dictionary=aruco_dict, \n",
    "                                                     parameters=parameters,\n",
    "                                                     cameraMatrix=camera_matrix, \n",
    "                                                     distCoeff=camera_distortion)\n",
    "        \n",
    "        #-- If there is a id and compare if id is equal to the searched\n",
    "        if ids != None and ids[0] == id_to_find:\n",
    "            \n",
    "            update_fps_detect()\n",
    "            \n",
    "            #-- ret= [rvec,tvec, ?]\n",
    "            #-- array of rotation and position of each marker in camera frame\n",
    "            #-- rvec = [[rvec_1, [rvec2], ...]]  attitude of the marker respect to camera frame\n",
    "            #-- tvec = [[tvec_1, [tvec2], ...]]  position of the marker in camera frame\n",
    "            ret = aruco.estimatePoseSingleMarkers(corners, marker_size, camera_matrix, camera_distortion)\n",
    "\n",
    "            #-- Unpack the output, get only the first\n",
    "            rvec, tvec = ret[0][0,0,:], ret[1][0,0,:]\n",
    "\n",
    "            #-- Draw the detected marker and put a reference frame over it\n",
    "            aruco.drawDetectedMarkers(imgRGB, corners)\n",
    "            aruco.drawAxis(imgRGB, camera_matrix, camera_distortion, rvec, tvec, 40)\n",
    "            \n",
    "            #-- Obtain the rotation matrix tag->camera\n",
    "            R_ct = np.matrix(cv2.Rodrigues(rvec)[0])\n",
    "            R_tc = R_ct.T # function transpose() with '.T'\n",
    "            #print(\"rotação transposta:\",R_tc)\n",
    "            \n",
    "            #-- Get the attitude in terms of euler 321 (Needs to be flipped first)\n",
    "            roll_marker, pitch_marker, yaw_marker = rotationMatrixToEulerAngles(R_tc)\n",
    "            \n",
    "            #-- Now get Position and attitude f the camera respect to the marker\n",
    "            pos_camera = -R_tc*np.matrix(tvec).T\n",
    "            roll_camera, pitch_camera, yaw_camera = rotationMatrixToEulerAngles(R_flip*R_tc)\n",
    "            \n",
    "            ###############################################################################\n",
    "            #-- Print the tag position in camera frame\n",
    "            str_position = \"MARKER Position x=%4.0f  y=%4.0f  z=%4.0f \"%(tvec[0], tvec[1], tvec[2])\n",
    "            cv2.putText(imgRGB, str_position, (0, 50), font, 1, (255, 255, 0), 1, cv2.LINE_AA)\n",
    "            \n",
    "            #-- Print the marker's attitude respect to camera frame\n",
    "            str_attitude = \"MARKER Attitude r=%4.0f  p=%4.0f  y=%4.0f\"%(math.degrees(roll_marker),math.degrees(pitch_marker),\n",
    "                                math.degrees(yaw_marker))\n",
    "            cv2.putText(imgRGB, str_attitude, (0, 100), font, 1, (255, 255, 0), 1, cv2.LINE_AA)\n",
    "            \n",
    "            \n",
    "            #-- Print the tag position in camera frame\n",
    "            str_position = \"CAMERA Position x=%4.0f  y=%4.0f  z=%4.0f\"%(pos_camera[0], pos_camera[1], pos_camera[2])\n",
    "            cv2.putText(imgRGB, str_position, (0, 150), font, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "            #-- Get the attitude of the camera respect to the frame\n",
    "            str_attitude = \"CAMERA Attitude r=%4.0f  p=%4.0f  y=%4.0f\"%(math.degrees(roll_camera),math.degrees(pitch_camera),\n",
    "                                math.degrees(yaw_camera))\n",
    "            cv2.putText(imgRGB, str_attitude, (0, 200), font, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "            \n",
    "            ###############################################################################\n",
    "\n",
    "            #-- Display the resulting frame\n",
    "            cv2.imshow(windowName,imgRGB)\n",
    "            \n",
    "            # print 'Camera X = %.1f  Y = %.1f  Z = %.1f  - fps = %.0f'%(pos_camera[0], pos_camera[1], pos_camera[2],fps_detect)\n",
    "            # print('Marker X = {:.2f}  Y = {:.2f}  Z = {:.2f}  - fps = {:.2f}'.format(tvec[0], tvec[1], tvec[2],fps_detect))\n",
    "            #print('pos - X = {:.2f}  Y = {:.2f}  Z = {:.2f}'.format(pos[0], pos[1], pos[2]))\n",
    "            \n",
    "            #-- correction of angle yaw\n",
    "            if math.degrees(yaw_camera)>=10:\n",
    "                #tgpos=[pos[0],pos[1],pos[2]+1]# Movimenta para a esquerda\n",
    "                #vrep.simxSetObjectPosition(clientID,tgHandle,tgHandle,tgpos,vrep.simx_opmode_oneshot)\n",
    "                tgori=[ori[0],ori[1],ori[2]+(2*np.pi/180)]\n",
    "                vrep.simxSetObjectOrientation(clientID,tgHandle,-1,tgori,vrep.simx_opmode_oneshot)\n",
    "            elif math.degrees(yaw_camera)>=1 and math.degrees(yaw_camera)<10:\n",
    "                tgori=[ori[0],ori[1],ori[2]+(0.3*np.pi/180)]\n",
    "                vrep.simxSetObjectOrientation(clientID,tgHandle,-1,tgori,vrep.simx_opmode_oneshot)\n",
    "                #print('ori - {} '.format(tgori))\n",
    "            elif math.degrees(yaw_camera)<=-10:\n",
    "                tgori=[ori[0],ori[1],ori[2]-(2*np.pi/180)]\n",
    "                vrep.simxSetObjectOrientation(clientID,tgHandle,-1,tgori,vrep.simx_opmode_oneshot)\n",
    "            elif math.degrees(yaw_camera)<=-1 and math.degrees(yaw_camera)>-10:\n",
    "                tgori=[ori[0],ori[1],ori[2]-(0.3*np.pi/180)]\n",
    "                vrep.simxSetObjectOrientation(clientID,tgHandle,-1,tgori,vrep.simx_opmode_oneshot)\n",
    "            \n",
    "            #-- Exit on ESC\n",
    "            if cv2.waitKey(1) == 27:\n",
    "                break\n",
    "        \n",
    "        else:\n",
    "            print('Nothing detected - fps = {:.2f}'.format(fps_read))\n",
    "            \n",
    "            #-- Display the resulting frame\n",
    "            cv2.imshow(windowName,imgRGB)\n",
    "            #-- Exit on ESC\n",
    "            if cv2.waitKey(1) == 27:\n",
    "                break\n",
    "\n",
    "    #-- Now close the connection to V-REP:\n",
    "    vrep.simxFinish(clientID)\n",
    "\n",
    "else:\n",
    "    print ('Failed connecting to remote API server')\n",
    "print ('Program ended')\n",
    "\n",
    "#-- destroy all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
